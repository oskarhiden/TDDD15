---
title: "Lab4"
author: "Oskar Hid√©n - oskhi827"
date: "10/18/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## Part 1 - Implementing GP Regression
```{r}
#install.packages('kernlab')
library(kernlab)

# Computing the whole covariance matrix K from the kernel.
cov_function = function(X, Xstar){
  return(kernelMatrix(kernel = SEkernel, x=X, y=Xstar)) 
}

# Algorithm 2.1 sunns in n^3/6 instead of O(n^3). GP can be estimated faster, O(n) with eg. KISS-GP
posteriorGP = function(X_input, y_targets, k_cov_function, sigmaNoise=1, XStar){
  A = k_cov_function(X_input, X_input)
  A = A + diag(length(X_input))*sigmaNoise^2
  L = t(chol(A)) # chol Returns t(L)
  L_y = solve(L, y_targets)
  alpha = solve(t(L), L_y)
  
  k_star = k_cov_function(X_input, XStar)
  f_star = t(k_star)%*%alpha
  
  v = solve(L,k_star)
  V_f_star = k_cov_function(XStar, XStar) - t(v)%*%v
  return(list("mean"=f_star, "cov" = V_f_star))
}

sigma_f = 1
ell = 0.3
SEkernel <- rbfdot(sigma = 1/(2*ell^2)) # Reparametrize the rbfdot (which is the SE kernel) in kernlab.
sigma_n = 0.1

# 2 - Update prior with a signle observation
x=0.4
y=0.719
xGrid <- seq(-1,1,length=20) # x_star

posterior = posteriorGP(x, y, cov_function, sigma_n, xGrid)

plot(xGrid, posterior$mean, ylim = c(-2.5,2.5)) # posterior mean
std_dev = sqrt(diag(posterior$cov))
points(xGrid, posterior$mean + 1.96*std_dev, col="blue")
points(xGrid, posterior$mean - 1.96*std_dev, col="blue")

# 3 - Update posterior with another point. (by recalculating posterior wiht Algorithm 2.1)
x = c(0.4, -0.6)
y = c(0.719 , -0.044)
posterior = posteriorGP(x, y, cov_function, sigma_n, xGrid)

plot(xGrid, posterior$mean, ylim = c(-2.5,2.5)) # posterior mean
std_dev = sqrt(diag(posterior$cov))
points(xGrid, posterior$mean + 1.96*std_dev, col="blue")
points(xGrid, posterior$mean - 1.96*std_dev, col="blue")


# 4 - Calculate the posterior with five observations.
x = c(-1.0, -0.6, -0.2, 0.4, 0.8)
y = c(0.768, -0.044, -0.940, 0.719, -0.664)
posterior = posteriorGP(x, y, cov_function, sigma_n, xGrid)

plot(xGrid, posterior$mean, ylim = c(-2.5,2.5)) # posterior mean
std_dev = sqrt((diag(posterior$cov)))
points(xGrid, posterior$mean + 1.96*std_dev, col="blue")
points(xGrid, posterior$mean - 1.96*std_dev, col="blue")

# 5 - Redo (4) with the same sigma_f but with a higher ell.
sigma_f = 1
ell = 1
SEkernel <- rbfdot(sigma = 1/(2*ell^2))

x = c(-1.0, -0.6, -0.2, 0.4, 0.8)
y = c(0.768, -0.044, -0.940, 0.719, -0.664)
posterior = posteriorGP(x, y, cov_function, sigma_n, xGrid)

plot(xGrid, posterior$mean, ylim = c(-2.5,2.5)) # posterior mean
std_dev = sqrt((diag(posterior$cov)))
points(xGrid, posterior$mean + 1.96*std_dev, col="blue")
points(xGrid, posterior$mean - 1.96*std_dev, col="blue")

```

The two plots has the same sigma_f but different l-values. The last plot is smoother, with a higher l value. And the 95% confidence intervall is closer to posterior mean. 


## Part 2 - GP Regression with kernlab
```{r}
temp = read.csv("https://github.com/STIMALiU/AdvMLCourse/raw/master/GaussianProcess/Code/TempTullinge.csv",
                header=TRUE,sep=";")
time = (1:2190)
nr_year = 2190/365
day = rep((1:365), nr_year)

reduce_data = function(array , nth){
  array[seq(1, length(array), nth)]
}

day = reduce_data(temp$temp,5)
time = reduce_data(time, 5)
day = reduce_data(day, 5)

set_se_kernel = function(ell, sigma_f){
  se_kernel = function(x , y){
    r_square = sum((x-y)*(x-y)) # Euclidian distance^2
    return(sigma_f^2*exp(-r_square/(2*ell^2)))
  }
  class(se_kernel) <- "kernel"
  return(se_kernel)
}

se_kernel = set_se_kernel(ell=1, sigma_f=1)
# Evaluate kernel in x=1 and x'=2
se_kernel(1,2)

k = function(x, x_star){
  return(kernelMatrix(kernel = se_kernel, x=x, y=x_star))
}
# Evaluate the covariance matrix, k
x = c(1, 3, 4)
x_star = c(2, 3, 4)
k(x, x_star)


# 2 - Find f* with function: gausspr(kernlab)
sigma_f = 20
ell = 0.2
se_kernel = set_se_kernel(ell=ell, sigma_f=sigma_f)

# Find sigma_n
quadratic_reg = lm(day ~ time + I(time^2))
sigma_n = sd(quadratic_reg$residuals)

gp_model = gausspr(x = time, y = day, type="regression", kernel=se_kernel, var = sigma_n^2, variance.model=TRUE)

mean_pred= predict(gp_model, time)
plot(time, day)
points(time, mean_pred, type = "l", col="red")
lines(time, mean_pred+1.96*predict(gp_model, time, type="sdeviation")) # wrong due to scaleing done by gausspr....

# 3 - Scale and calculate with Algorithm 2.1
mean = mean(day)
st_dev = sd(day)
day_scale = scale(day)

# Find sigma_n
time_scale = scale(time)
quadratic_reg = lm(day ~ time_scale + I(time_scale^2))
sigma_n = sd(quadratic_reg$residuals)

post_gp = posteriorGP(time_scale, day_scale, k, sigma_n, time_scale)
st_dev_new = sqrt(diag(post_gp$cov))
mean_pred_new = post_gp$mean*st_dev+mean
plot(time, day)
lines(time, mean_pred_new, col ="red")
lines(time, mean_pred_new+1.96*st_dev_new, col="blue")
lines(time, mean_pred_new-1.96*st_dev_new, col="blue")

# 4 - use of Day
day_scale = scale(day)
#Find sigma_n
time_scale = scale(time)
quadratic_reg = lm(day ~ day_scale + I(day_scale^2))
sigma_n = sd(quadratic_reg$residuals)

# old plot
plot(time, day)
lines(time, mean_pred_new, col ="red")
lines(time, mean_pred_new+1.96*st_dev_new, col="blue")
lines(time, mean_pred_new-1.96*st_dev_new, col="blue")

post_gp = posteriorGP(day_scale, day_scale, k, sigma_n, day_scale)
st_dev_new = sqrt(diag(post_gp$cov))
mean_pred_new = post_gp$mean*st_dev+mean
lines(time, mean_pred_new, col ="black")
lines(time, mean_pred_new+1.96*st_dev_new, col="green")
lines(time, mean_pred_new-1.96*st_dev_new, col="green")


# 5 - gen periodic kernel
sigma_f = 20
ell_1 = 1
ell_2 = 10
d = 365/sd(time)

set_gen_kernel = function(ell_1, ell_2, sigma_f, d){
  gen_kernel = function(x , y){
    r_square = sum((x-y)*(x-y)) #euclidian distance ^2
 
    return(sigma_f^2* exp(-sin(pi*sqrt(r_square)/d)/(ell_1^2)) * exp(-r_square/(2*ell_2^2)))
  }
  class(gen_kernel) <- "kernel"
  return(gen_kernel)
}

gen_kernel = set_gen_kernel(ell_1, ell_2, sigma_f, d)
k_gen = function(x, x_star){
  return(kernelMatrix(kernel = gen_kernel, x=x, y=x_star))
}

gp_model = gausspr(x = time, y = day, type="regression", kernel=se_kernel, var = sigma_n^2, variance.model=TRUE)

mean_pred = predict(gp_model, time)
plot(time, day)
points(time, mean_pred, type = "l", col="red")



```

## Part 3 - GP Classification with kernlab
```{r}
#install.packages("AtmRay") # To make 2D grid like in Matlab's meshgrid.
#library(AtmRay)
```
